{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4e79fd-acaf-405e-af2f-3323e5dcab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is data encoding? How is it useful in data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff3e9a-b701-4b4e-ac5f-4a0ed8d0563a",
   "metadata": {},
   "source": [
    "ANS = Data Encoding\n",
    "\n",
    "Data encoding refers to the process of converting data from one format to another. This process ensures that data is in a suitable format for various applications, including storage, transmission, and processing. Encoding can involve transforming data into a more compact or standardized form, making it easier to handle and interpret.\n",
    "\n",
    "Types of Data Encoding:\n",
    "\n",
    "Text Encoding: Converting text into binary format using schemes like ASCII, UTF-8, etc.\n",
    "Image Encoding: Converting images into formats like JPEG, PNG, etc.\n",
    "Audio/Video Encoding: Converting multimedia data into formats like MP3, MP4, etc.\n",
    "Data Compression: Reducing the size of data for efficient storage and transmission, using methods like ZIP, RAR, etc.\n",
    "\n",
    "Feature Encoding: In data science, specifically, transforming categorical data into numerical format.\n",
    "Importance of Data Encoding in Data Science\n",
    "Preprocessing for Machine Learning:\n",
    "\n",
    "Categorical Data Handling: Many machine learning algorithms require numerical input. Encoding categorical data (like names, labels) into numerical format (using one-hot encoding, label encoding, etc.) allows algorithms to process these features.\n",
    "Normalization/Standardization: Ensuring features have similar scales through techniques like min-max scaling, z-score normalization, etc.\n",
    "Improved Model Performance:\n",
    "\n",
    "Proper encoding can enhance the performance of models by making data more interpretable and reducing noise.\n",
    "Encoded data often results in more accurate predictions and better generalization.\n",
    "Data Transmission and Storage:\n",
    "\n",
    "Efficient encoding methods compress data, reducing storage requirements and transmission time.\n",
    "Encoding ensures data integrity and security during transmission.\n",
    "Interoperability:\n",
    "\n",
    "Standardized encoding formats ensure that data can be seamlessly shared and used across different systems and platforms.\n",
    "Facilitating Complex Analyses:\n",
    "\n",
    "Encoding methods, like embedding in NLP, transform text data into vector formats that capture semantic meaning, allowing for more complex and meaningful analyses.\n",
    "Common Encoding Techniques in Data Science\n",
    "Label Encoding:\n",
    "\n",
    "Converts categorical labels into numeric values.\n",
    "Useful for ordinal data where order matters.\n",
    "One-Hot Encoding:\n",
    "\n",
    "Converts categorical variables into a series of binary variables.\n",
    "Prevents algorithms from assuming an ordinal relationship between categories.\n",
    "Binary Encoding:\n",
    "\n",
    "Encodes categories as binary numbers.\n",
    "Reduces dimensionality compared to one-hot encoding.\n",
    "Frequency Encoding:\n",
    "\n",
    "Encodes categories based on the frequency of their occurrence.\n",
    "Useful for handling high cardinality categorical features.\n",
    "Target Encoding:\n",
    "\n",
    "Replaces categories with the mean of the target variable.\n",
    "Useful in certain predictive modeling contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bc2c42-d8df-4229-8342-a6271a131c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062418c6-65e0-4e22-b488-a26c5a2352fa",
   "metadata": {},
   "source": [
    "Nominal Encoding\n",
    "\n",
    "Nominal encoding, also known as categorical encoding, is a technique used to convert categorical data into a format that can be provided to machine learning algorithms to improve their performance. Categorical data refers to data that can take on a limited, and usually fixed, number of possible values, representing different categories. Nominal encoding specifically handles data where the categories do not have an intrinsic order (i.e., they are nominal).\n",
    "\n",
    "Common Techniques for Nominal Encoding\n",
    "\n",
    "One-Hot Encoding:\n",
    "\n",
    "Converts each category value into a new binary column.\n",
    "Each column corresponds to one category and has a value of 0 or 1.\n",
    "\n",
    "Label Encoding:\n",
    "\n",
    "Converts each category value into a numeric label.\n",
    "Typically used for ordinal data but can be used for nominal data with caution.\n",
    "\n",
    "Binary Encoding:\n",
    "\n",
    "Converts categories into binary digits.\n",
    "More space-efficient than one-hot encoding.\n",
    "Example Scenario: E-Commerce Customer Segmentation\n",
    "Let's consider a real-world scenario where you are working on customer segmentation for an e-commerce platform. You want to use machine learning algorithms to segment customers based on various features, including their preferred payment method.\n",
    "\n",
    "Step-by-Step Example Using One-Hot Encoding\n",
    "Identify the Categorical Feature:\n",
    "\n",
    "Suppose you have a categorical feature named PaymentMethod with the following possible values: [\"Credit Card\", \"Debit Card\", \"PayPal\", \"Bank Transfer\"].\n",
    "Convert the Feature using One-Hot Encoding:\n",
    "\n",
    "Using one-hot encoding, each payment method is converted into a separate binary column.\n",
    "\n",
    "| CustomerID | PaymentMethod |\n",
    "|------------|---------------|\n",
    "| 1          | Credit Card   |\n",
    "| 2          | PayPal        |\n",
    "| 3          | Debit Card    |\n",
    "| 4          | Credit Card   |\n",
    "| 5          | Bank Transfer |\n",
    "\n",
    "\n",
    "| CustomerID | Credit Card | Debit Card | PayPal | Bank Transfer |\n",
    "|------------|-------------|------------|--------|---------------|\n",
    "| 1          | 1           | 0          | 0      | 0             |\n",
    "| 2          | 0           | 0          | 1      | 0             |\n",
    "| 3          | 0           | 1          | 0      | 0             |\n",
    "| 4          | 1           | 0          | 0      | 0             |\n",
    "| 5          | 0           | 0          | 0      | 1             |\n",
    "\n",
    "\n",
    "Use the Encoded Data for Machine Learning:\n",
    "\n",
    "The one-hot encoded data can now be used as input features for machine learning models such as clustering algorithms (e.g., K-Means) to segment customers based on their payment methods along with other features.\n",
    "Benefits and Considerations\n",
    "Benefits:\n",
    "\n",
    "Ensures that machine learning models do not assume any ordinal relationship between categories.\n",
    "Allows the inclusion of categorical data in models that require numerical input.\n",
    "Considerations:\n",
    "\n",
    "One-hot encoding can lead to high dimensionality, especially with features having many categories.\n",
    "Binary encoding or other techniques may be more space-efficient for high-cardinality features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968ec016-8604-4abf-9c13-1ee89d65a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1b259-f34a-43f5-9194-1a953fd939f6",
   "metadata": {},
   "source": [
    "ANS = Situations Where Nominal Encoding is Preferred Over One-Hot Encoding\n",
    "Nominal encoding, in the context of this question, typically refers to encoding methods that are more space-efficient or suitable for certain types of categorical data compared to one-hot encoding. These methods include label encoding, binary encoding, target encoding, or frequency encoding. Nominal encoding may be preferred over one-hot encoding in the following situations:\n",
    "\n",
    "High Cardinality: When the categorical feature has a large number of unique values, one-hot encoding can lead to a very high-dimensional sparse matrix, which can be computationally expensive and may lead to overfitting. In such cases, more compact encoding methods like binary encoding or frequency encoding are preferred.\n",
    "\n",
    "Memory Efficiency: When there are constraints on memory usage, one-hot encoding might not be feasible due to the high dimensionality it introduces. Compact encoding methods reduce memory usage.\n",
    "\n",
    "Ordinal Nature Misinterpretation: While one-hot encoding prevents ordinal misinterpretation, some tasks might still benefit from using label encoding or target encoding, especially when the encoded values are used in algorithms that can handle ordinal data appropriately.\n",
    "\n",
    "Model Compatibility: Some models, like tree-based methods (e.g., decision trees, random forests), can handle categorical variables directly or may benefit from label encoding over one-hot encoding.\n",
    "\n",
    "Practical Example: Frequency Encoding in Customer Behavior Analysis\n",
    "Scenario\n",
    "Suppose you are working on a customer behavior analysis project for an online retail store. You have a categorical feature ProductCategory with a high cardinality, consisting of 100 unique product categories. You need to prepare this feature for a machine learning model to predict customer purchase behavior.\n",
    "\n",
    "Step-by-Step Example Using Frequency Encoding\n",
    "Identify the Categorical Feature:\n",
    "\n",
    "Feature: ProductCategory\n",
    "Unique values: [\"Electronics\", \"Clothing\", \"Books\", \"Furniture\", ...] (100 unique categories)\n",
    "Apply Frequency Encoding:\n",
    "\n",
    "Calculate the frequency of each category in the dataset.\n",
    "\n",
    "Original data:\n",
    "\n",
    "| CustomerID | ProductCategory |\n",
    "|------------|-----------------|\n",
    "| 1          | Electronics     |\n",
    "| 2          | Books           |\n",
    "| 3          | Clothing        |\n",
    "| 4          | Electronics     |\n",
    "| 5          | Furniture       |\n",
    "\n",
    "\n",
    "Frequency encoding:\n",
    "\n",
    "| ProductCategory | Frequency |\n",
    "|-----------------|-----------|\n",
    "| Electronics     | 2         |\n",
    "| Books           | 1         |\n",
    "| Clothing        | 1         |\n",
    "| Furniture       | 1         |\n",
    "\n",
    "\n",
    "Encoded data:\n",
    "\n",
    "| CustomerID | ProductCategory |\n",
    "|------------|-----------------|\n",
    "| 1          | 2               |\n",
    "| 2          | 1               |\n",
    "| 3          | 1               |\n",
    "| 4          | 2               |\n",
    "| 5          | 1               |\n",
    "\n",
    "Use the Encoded Data for Machine Learning:\n",
    "\n",
    "The frequency-encoded data can now be used as input features for machine learning models to predict customer purchase behavior.\n",
    "Benefits of Frequency Encoding in This Scenario\n",
    "Reduced Dimensionality: The high cardinality of ProductCategory is efficiently managed by converting it into a single numeric feature, avoiding the high-dimensional sparse matrix that one-hot encoding would produce.\n",
    "Memory Efficiency: The encoded feature uses less memory, making it more suitable for large datasets.\n",
    "Model Performance: Tree-based models and some other machine learning algorithms can handle frequency-encoded data effectively, potentially leading to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f7427a-0ecb-4538-835b-186a139eded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding\n",
    "# technique would you use to transform this data into a format suitable for machine learning algorithms?\n",
    "# Explain why you made this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e535a21-911f-43d3-a645-5818bec3a402",
   "metadata": {},
   "source": [
    "ANS = Encoding Categorical Data with 5 Unique Values\n",
    "Given a dataset containing categorical data with 5 unique values, the choice of encoding technique depends on several factors, including the nature of the data, the machine learning algorithms you plan to use, and the computational resources available. Here are some encoding techniques to consider, along with a recommendation for the most suitable one:\n",
    "\n",
    "Encoding Techniques\n",
    "One-Hot Encoding:\n",
    "\n",
    "Description: Converts each category into a binary vector where only the index corresponding to the category is set to 1, and the rest are 0.\n",
    "\n",
    "Example:\n",
    "\n",
    "Categories: [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "Encoded:\n",
    "A -> [1, 0, 0, 0, 0]\n",
    "B -> [0, 1, 0, 0, 0]\n",
    "C -> [0, 0, 1, 0, 0]\n",
    "D -> [0, 0, 0, 1, 0]\n",
    "E -> [0, 0, 0, 0, 1]\n",
    "\n",
    "Pros:\n",
    "\n",
    "Prevents algorithms from assuming any ordinal relationship between categories.\n",
    "Suitable for most machine learning algorithms.\n",
    "\n",
    "Cons:\n",
    "Can lead to high-dimensional sparse data if the number of categories is large.\n",
    "\n",
    "Label Encoding:\n",
    "\n",
    "Description: Assigns a unique integer to each category.\n",
    "\n",
    "Example:\n",
    "\n",
    "Categories: [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "Encoded:\n",
    "A -> 0\n",
    "B -> 1\n",
    "C -> 2\n",
    "D -> 3\n",
    "E -> 4\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simple and efficient.\n",
    "No increase in dimensionality.\n",
    "\n",
    "Cons:\n",
    "Implicitly assumes an ordinal relationship between categories, which might not be appropriate.\n",
    "\n",
    "Binary Encoding:\n",
    "\n",
    "Description: Converts categories into binary numbers and then splits the digits into separate columns.\n",
    "\n",
    "Example\n",
    "\n",
    "Categories: [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "Encoded (assuming A=0, B=1, ..., E=4):\n",
    "A -> 000 -> [0, 0, 0]\n",
    "B -> 001 -> [0, 0, 1]\n",
    "C -> 010 -> [0, 1, 0]\n",
    "D -> 011 -> [0, 1, 1]\n",
    "E -> 100 -> [1, 0, 0]\n",
    "\n",
    "Pros:\n",
    "More space-efficient than one-hot encoding.\n",
    "Cons:\n",
    "Slightly more complex to implement and interpret.\n",
    "Recommended Technique: One-Hot Encoding\n",
    "For a dataset with only 5 unique categorical values, one-hot encoding is the most suitable technique. Here’s why:\n",
    "\n",
    "Dimensionality:\n",
    "\n",
    "With only 5 categories, one-hot encoding will result in 5 binary columns, which is manageable and not computationally intensive.\n",
    "No Assumption of Ordinality:\n",
    "\n",
    "One-hot encoding ensures that there is no implicit ordinal relationship between the categories, making it suitable for a wide range of machine learning algorithms.\n",
    "Compatibility:\n",
    "\n",
    "Most machine learning algorithms, including linear models, neural networks, and tree-based methods, handle one-hot encoded data effectively.\n",
    "\n",
    "Implementation Example\n",
    "\n",
    "Suppose you have a feature Color with values [\"Red\", \"Green\", \"Blue\", \"Yellow\", \"Black\"]\n",
    "\n",
    "| Color  |\n",
    "|--------|\n",
    "| Red    |\n",
    "| Green  |\n",
    "| Blue   |\n",
    "| Yellow |\n",
    "| Black  |\n",
    "\n",
    "One-hot encoded data:\n",
    "\n",
    "\n",
    "\n",
    "| Red | Green | Blue | Yellow | Black |\n",
    "|-----|-------|------|--------|-------|\n",
    "| 1   | 0     | 0    | 0      | 0     |\n",
    "| 0   | 1     | 0    | 0      | 0     |\n",
    "| 0   | 0     | 1    | 0      | 0     |\n",
    "| 0   | 0     | 0    | 1      | 0     |\n",
    "| 0   | 0     | 0    | 0      | 1     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6c4ca3-f627-424e-b73e-0885656b4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
    "# are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
    "# transform the categorical data, how many new columns would be created? Show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6fd8a-8a6f-4961-a194-0a3ec671b928",
   "metadata": {},
   "source": [
    "ANS = To determine how many new columns would be created when using nominal encoding to transform the categorical data, we need to know the specific encoding technique and the number of unique values in each categorical column. Let's assume we are using one-hot encoding, which is a common method for nominal data.\n",
    "\n",
    "Step-by-Step Calculation\n",
    "Identify the Categorical Columns:\n",
    "\n",
    "Let's assume the two categorical columns are Category1 and Category2.\n",
    "Count Unique Values in Each Categorical Column:\n",
    "\n",
    "Suppose Category1 has 4 unique values: [\"A\", \"B\", \"C\", \"D\"].\n",
    "Suppose Category2 has 3 unique values: [\"X\", \"Y\", \"Z\"].\n",
    "Apply One-Hot Encoding:\n",
    "\n",
    "One-hot encoding converts each unique value in a categorical column into a separate binary column.\n",
    "Calculation of New Columns\n",
    "Category1:\n",
    "\n",
    "Original column: 1\n",
    "One-hot encoded columns: 4 (one for each unique value)\n",
    "Category2:\n",
    "\n",
    "Original column: 1\n",
    "One-hot encoded columns: 3 (one for each unique value)\n",
    "Total Columns After Encoding\n",
    "Original Columns:\n",
    "\n",
    "Numerical columns: 3\n",
    "Categorical columns before encoding: 2\n",
    "New Columns Created:\n",
    "\n",
    "For Category1: 4 new columns (replacing the original 1 column)\n",
    "For Category2: 3 new columns (replacing the original 1 column)\n",
    "Total Columns After Encoding:\n",
    "\n",
    "Numerical columns: 3\n",
    "One-hot encoded columns for Category1: 4\n",
    "One-hot encoded columns for Category2: 3\n",
    "\n",
    "Final Column Count\n",
    "\n",
    "Total Columns=Numerical Columns+One-Hot Encoded Columns for Category1+One-Hot Encoded Columns for Category2\n",
    "\n",
    "Total Columns=3+4+3=10\n",
    "\n",
    "Therefore, after applying nominal (one-hot) encoding to the two categorical columns, the dataset will have 10 columns in total.\n",
    "\n",
    "Summary\n",
    "Original dataset: 5 columns (2 categorical, 3 numerical)\n",
    "After one-hot encoding: 10 columns (3 numerical, 7 one-hot encoded)\n",
    "3 numerical columns remain unchanged\n",
    "4 one-hot encoded columns from Category1\n",
    "3 one-hot encoded columns from Category2\n",
    "Thus, 5 new columns are created through the nominal encoding process, resulting in a total of 10 columns in the transformed dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd4072d-7af2-45c3-aefa-e12e0f625d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. You are working with a dataset containing information about different types of animals, including their\n",
    "# species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
    "# a format suitable for machine learning algorithms? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494df98-4495-4b92-8cf1-cb9e098d8600",
   "metadata": {},
   "source": [
    "ANS = Transforming Categorical Data for Animal Dataset\n",
    "For a dataset containing information about different types of animals, including their species, habitat, and diet, the encoding technique should ensure that the categorical data is properly transformed for use in machine learning algorithms without introducing unnecessary complexity or assuming ordinal relationships where none exist.\n",
    "\n",
    "Considerations for Choosing an Encoding Technique\n",
    "Nature of the Data:\n",
    "\n",
    "Species: Likely to have many unique values (high cardinality).\n",
    "Habitat: Might have a moderate number of unique values.\n",
    "Diet: Might have a few distinct categories.\n",
    "Model Compatibility:\n",
    "\n",
    "Most machine learning algorithms, particularly those based on distance (like K-Nearest Neighbors) or linear models, require numerical input without ordinal assumptions.\n",
    "Tree-based models (like decision trees or random forests) can handle categorical data differently, sometimes performing well with label encoding.\n",
    "Dimensionality and Sparsity:\n",
    "\n",
    "High-dimensional sparse matrices can result from one-hot encoding, which might be computationally expensive and lead to overfitting, especially for features with high cardinality.\n",
    "Recommended Encoding Techniques\n",
    "Given these considerations, here are the recommended encoding techniques for each categorical feature:\n",
    "\n",
    "Species: Assume high cardinality.\n",
    "\n",
    "Binary Encoding: Efficiently handles high cardinality by converting categories into binary digits, reducing the dimensionality compared to one-hot encoding.\n",
    "Habitat: Assume moderate cardinality.\n",
    "\n",
    "One-Hot Encoding: Suitable for features with a moderate number of unique values, ensuring no ordinal relationship is assumed and maintaining interpretability.\n",
    "Diet: Assume low cardinality.\n",
    "\n",
    "One-Hot Encoding: Simple and effective for features with a few unique values, ensuring compatibility with a wide range of algorithms.\n",
    "Justification for the Chosen Techniques\n",
    "Binary Encoding for Species:\n",
    "\n",
    "Efficiency: Reduces the number of columns compared to one-hot encoding, making it more memory efficient.\n",
    "Interpretability: Provides a balance between interpretability and dimensionality.\n",
    "One-Hot Encoding for Habitat and Diet:\n",
    "\n",
    "No Ordinal Assumption: Ensures that the machine learning algorithm does not assume any intrinsic order in the categories, which is crucial for nominal data.\n",
    "Model Compatibility: One-hot encoded data is compatible with most machine learning algorithms, including linear models and neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334b2f4a-47b5-4218-8ee8-413393f95187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
    "# company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
    "# monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
    "# data into numerical data? Provide a step-by-step explanation of how you would implement the encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b339e84-ca37-40ec-82cd-164a23ed8079",
   "metadata": {},
   "source": [
    "ANS = To predict customer churn for a telecommunications company using a dataset with features such as gender, age, contract type, monthly charges, and tenure, it's important to transform the categorical data into numerical data to make it suitable for machine learning algorithms. Here's a step-by-step explanation of how to implement the encoding:\n",
    "\n",
    "Step 1: Identify Categorical and Numerical Features\n",
    "Categorical Features:\n",
    "\n",
    "Gender (e.g., \"Male\", \"Female\")\n",
    "Contract Type (e.g., \"Month-to-Month\", \"One Year\", \"Two Year\")\n",
    "Numerical Features:\n",
    "\n",
    "Age\n",
    "Monthly Charges\n",
    "Tenure\n",
    "Step 2: Choose Encoding Techniques\n",
    "For the categorical features, we need to choose appropriate encoding techniques:\n",
    "\n",
    "Gender: This feature has two unique values (\"Male\" and \"Female\").\n",
    "\n",
    "One-Hot Encoding: Suitable for binary categorical data as it prevents ordinal relationships.\n",
    "Contract Type: This feature has three unique values (\"Month-to-Month\", \"One Year\", \"Two Year\").\n",
    "\n",
    "One-Hot Encoding: Suitable for features with a few unique values, ensuring no ordinal relationship is implied.\n",
    "Step 3: Implement Encoding\n",
    "One-Hot Encoding for Gender\n",
    "\n",
    "Original data:\n",
    "\n",
    "| Gender |\n",
    "|--------|\n",
    "| Male   |\n",
    "| Female |\n",
    "| Female |\n",
    "| Male   |\n",
    "\n",
    "One-hot encoded data:\n",
    "\n",
    "| Gender_Male | Gender_Female |\n",
    "|-------------|---------------|\n",
    "| 1           | 0             |\n",
    "| 0           | 1             |\n",
    "| 0           | 1             |\n",
    "| 1           | 0             |\n",
    "\n",
    "One-Hot Encoding for Contract Type\n",
    "Original data:\n",
    "\n",
    "| ContractType   |\n",
    "|----------------|\n",
    "| Month-to-Month |\n",
    "| One Year       |\n",
    "| Two Year       |\n",
    "| Month-to-Month |\n",
    "\n",
    "One-hot encoded data:\n",
    "\n",
    "\n",
    "| ContractType_Month-to-Month | ContractType_OneYear | ContractType_TwoYear |\n",
    "|-----------------------------|----------------------|----------------------|\n",
    "| 1                           | 0                    | 0                    |\n",
    "| 0                           | 1                    | 0                    |\n",
    "| 0                           | 0                    | 1                    |\n",
    "| 1                           | 0                    | 0                    |\n",
    "\n",
    "Step 4: Integrate Encoded Features with Numerical Features\n",
    "Original numerical data:\n",
    "\n",
    "| Age | MonthlyCharges | Tenure |\n",
    "|-----|----------------|--------|\n",
    "| 30  | 29.85          | 5      |\n",
    "| 45  | 56.95          | 20     |\n",
    "| 50  | 53.85          | 36     |\n",
    "| 25  | 42.30          | 12     |\n",
    "\n",
    "Combined data:\n",
    "\n",
    "| Age | MonthlyCharges | Tenure | Gender_Male | Gender_Female | ContractType_Month-to-Month | ContractType_OneYear | ContractType_TwoYear |\n",
    "|-----|----------------|--------|-------------|---------------|-----------------------------|----------------------|----------------------|\n",
    "| 30  | 29.85          | 5      | 1           | 0             | 1                           | 0                    | 0                    |\n",
    "| 45  | 56.95          | 20     | 0           | 1             | 0                           | 1                    | 0                    |\n",
    "| 50  | 53.85          | 36     | 0           | 1             | 0                           | 0                    | 1                    |\n",
    "| 25  | 42.30          | 12     | 1           | 0             | 1                           | 0                    | 0                    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175de950-5454-468e-95dd-8a4a4ebef7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
